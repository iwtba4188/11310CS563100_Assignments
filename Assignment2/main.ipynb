{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-arithmetic\n",
    "\n",
    "## Dataset\n",
    "- [Arithmetic dataset](https://drive.google.com/file/d/1cMuL3hF9jefka9RyF4gEBIGGeFGZYHE-/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn\n",
    "# ! pip install opencc\n",
    "# ! pip install -U scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.utils.rnn\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opencc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2285313</td>\n",
       "      <td>14*(43+20)=</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317061</td>\n",
       "      <td>(6+1)*5=</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718770</td>\n",
       "      <td>13+32+29=</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170195</td>\n",
       "      <td>31*(3-11)=</td>\n",
       "      <td>-248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2581417</td>\n",
       "      <td>24*49+1=</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          src   tgt\n",
       "0     2285313  14*(43+20)=   882\n",
       "1      317061     (6+1)*5=    35\n",
       "2      718770    13+32+29=    74\n",
       "3      170195   31*(3-11)=  -248\n",
       "4     2581417     24*49+1=  1177"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_path, \"arithmetic_train.csv\"))\n",
    "df_eval = pd.read_csv(os.path.join(data_path, \"arithmetic_eval.csv\"))\n",
    "df_train.head()\n",
    "\n",
    "# shihtl> tmp reducing training size\n",
    "# df_train = df_train[:12800]\n",
    "# df_eval = df_eval[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input data to string\n",
    "df_train[\"tgt\"] = df_train[\"tgt\"].apply(lambda x: str(x))\n",
    "df_train[\"src\"] = df_train[\"src\"].add(df_train[\"tgt\"])\n",
    "df_train[\"len\"] = df_train[\"src\"].apply(lambda x: len(x))\n",
    "\n",
    "df_eval[\"tgt\"] = df_eval[\"tgt\"].apply(lambda x: str(x))\n",
    "df_eval[\"src\"] = df_eval[\"src\"].add(df_eval[\"tgt\"])\n",
    "df_eval[\"len\"] = df_eval[\"src\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2285313</td>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>882</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317061</td>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718770</td>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170195</td>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>-248</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2581417</td>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>1177</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             src   tgt  len\n",
       "0     2285313  14*(43+20)=882   882   14\n",
       "1      317061      (6+1)*5=35    35   10\n",
       "2      718770     13+32+29=74    74   11\n",
       "3      170195  31*(3-11)=-248  -248   14\n",
       "4     2581417    24*49+1=1177  1177   12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dictionary\n",
    " - The model cannot perform calculations directly with plain text.\n",
    " - Convert all text (numbers/symbols) into numerical representations.\n",
    " - Special tokens\n",
    "    - '&lt;pad&gt;'\n",
    "        - Each sentence within a batch may have different lengths.\n",
    "        - The length is padded with '&lt;pad&gt;' to match the longest sentence in the batch.\n",
    "    - '&lt;eos&gt;'\n",
    "        - Specifies the end of the generated sequence.\n",
    "        - Without '&lt;eos&gt;', the model will not know when to stop generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 18\n",
      "{'<pad>': 0, '<eos>': 1, '(': 2, ')': 3, '*': 4, '+': 5, '-': 6, '0': 7, '1': 8, '2': 9, '3': 10, '4': 11, '5': 12, '6': 13, '7': 14, '8': 15, '9': 16, '=': 17}\n",
      "{0: '<pad>', 1: '<eos>', 2: '(', 3: ')', 4: '*', 5: '+', 6: '-', 7: '0', 8: '1', 9: '2', 10: '3', 11: '4', 12: '5', 13: '6', 14: '7', 15: '8', 16: '9', 17: '='}\n"
     ]
    }
   ],
   "source": [
    "char_to_id = {\n",
    "    \"<pad>\": 0,\n",
    "    \"<eos>\": 1,\n",
    "}\n",
    "\n",
    "id_to_char = {}\n",
    "\n",
    "\n",
    "# write your code here\n",
    "# Build a dictionary and give every token in the train dataset an id\n",
    "# The dictionary should contain <eos> and <pad>\n",
    "# char_to_id is to conver charactors to ids, while id_to_char is the opposite\n",
    "\n",
    "# shihtl> 這裡遍歷所有的 lines in df_train[\"src\"] 中所有的 char，但每次都遍歷有點多餘，目前不會有新的 char，所以執行一次之後改成直接指定 char_to_id\n",
    "# shihtl> method 1.0: Using ASCII order as id order\n",
    "# unique_chars = []\n",
    "# for line in df_train[\"src\"]:\n",
    "#     for char in line:\n",
    "#         if char not in unique_chars:\n",
    "#             unique_chars.append(char)\n",
    "# unique_chars.sort()\n",
    "\n",
    "# for idx, val in enumerate(unique_chars, start=2):\n",
    "#     char_to_id[val] = idx\n",
    "\n",
    "# shihtl> method 1.1: Result of method 1.0, but faster\n",
    "char_to_id = {\n",
    "    \"<pad>\": 0,\n",
    "    \"<eos>\": 1,\n",
    "    \"(\": 2,\n",
    "    \")\": 3,\n",
    "    \"*\": 4,\n",
    "    \"+\": 5,\n",
    "    \"-\": 6,\n",
    "    \"0\": 7,\n",
    "    \"1\": 8,\n",
    "    \"2\": 9,\n",
    "    \"3\": 10,\n",
    "    \"4\": 11,\n",
    "    \"5\": 12,\n",
    "    \"6\": 13,\n",
    "    \"7\": 14,\n",
    "    \"8\": 15,\n",
    "    \"9\": 16,\n",
    "    \"=\": 17,\n",
    "}\n",
    "\n",
    "# # shihtl> This section of code was assisted by GitHub Copilot, and modified manually.\n",
    "# # shihtl> method 2.0: count all char's appear times, larger appear times will have smaller id\n",
    "# appear_times = {}\n",
    "# for line in df_train[\"src\"]:\n",
    "#     for char in line:\n",
    "#         if char not in appear_times:\n",
    "#             appear_times[char] = 1\n",
    "#         else:\n",
    "#             appear_times[char] += 1\n",
    "# appear_times = sorted(appear_times.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(appear_times)\n",
    "\n",
    "# for idx, val in enumerate(appear_times, start=2):\n",
    "#     char_to_id[val[0]] = idx\n",
    "# # shihtl> Section end.\n",
    "\n",
    "# shihtl> gen id_to_char\n",
    "for key, val in char_to_id.items():\n",
    "    id_to_char[val] = key\n",
    "\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "\n",
    "print(\"Vocab size: {}\".format(vocab_size))\n",
    "print(char_to_id)\n",
    "print(id_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    " - The data is processed into the format required for the model's input and output.\n",
    " - Example: 1+2-3=0\n",
    "     - Model input: 1 + 2 - 3 = 0\n",
    "     - Model output: / / / / / 0 &lt;eos&gt;  (the '/' can be replaced with &lt;pad&gt;)\n",
    "     - The key for the model's output is that the model does not need to predict the next character of the previous part. What matters is that once the model sees '=', it should start generating the answer, which is '0'. After generating the answer, it should also generate&lt;eos&gt;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             src   tgt  len  \\\n",
      "0     2285313  14*(43+20)=882   882   14   \n",
      "1      317061      (6+1)*5=35    35   10   \n",
      "2      718770     13+32+29=74    74   11   \n",
      "3      170195  31*(3-11)=-248  -248   14   \n",
      "4     2581417    24*49+1=1177  1177   12   \n",
      "\n",
      "                                        char_id_list  \\\n",
      "0  [2, 4, 9, 10, 4, 5, 8, 3, 13, 11, 6, 15, 15, 3...   \n",
      "1             [10, 14, 8, 2, 11, 9, 12, 6, 5, 12, 1]   \n",
      "2             [2, 5, 8, 5, 3, 8, 3, 17, 6, 16, 4, 1]   \n",
      "3   [5, 2, 9, 10, 5, 7, 2, 2, 11, 6, 7, 3, 4, 15, 1]   \n",
      "4         [3, 4, 9, 4, 17, 8, 2, 6, 2, 2, 16, 16, 1]   \n",
      "\n",
      "                                     label_id_list  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 15, 3, 1]  \n",
      "1               [0, 0, 0, 0, 0, 0, 0, 0, 5, 12, 1]  \n",
      "2            [0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 4, 1]  \n",
      "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 4, 15, 1]  \n",
      "4        [0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 16, 16, 1]  \n",
      "   Unnamed: 0             src  tgt  len  \\\n",
      "0     2573208    48+43+34=125  125   12   \n",
      "1     1630340  30-(48+13)=-31  -31   14   \n",
      "2      549277  (21*31)+10=661  661   14   \n",
      "3      133957     2-27-10=-35  -35   11   \n",
      "4     1279828  (15*20)+24=324  324   14   \n",
      "\n",
      "                                        char_id_list  \\\n",
      "0          [4, 15, 8, 4, 5, 8, 5, 4, 6, 2, 3, 12, 1]   \n",
      "1  [5, 13, 7, 10, 4, 15, 8, 2, 5, 11, 6, 7, 5, 2, 1]   \n",
      "2  [10, 3, 2, 9, 5, 2, 11, 8, 2, 13, 6, 14, 14, 2...   \n",
      "3            [3, 7, 3, 16, 7, 2, 13, 6, 7, 5, 12, 1]   \n",
      "4  [10, 2, 12, 9, 3, 13, 11, 8, 3, 4, 6, 5, 3, 4, 1]   \n",
      "\n",
      "                                     label_id_list  \n",
      "0         [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 12, 1]  \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 2, 1]  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14, 2, 1]  \n",
      "3            [0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 12, 1]  \n",
      "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 3, 4, 1]  \n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "def zero_before_eq_sign(row: list):\n",
    "    \"\"\"把第一個等號之前的項次，都變成 encoded <pad>\"\"\"\n",
    "    idx = row.index(char_to_id[\"=\"])\n",
    "\n",
    "    return [char_to_id[\"<pad>\"]] * (idx + 1) + row[idx + 1 :]\n",
    "\n",
    "\n",
    "for df in [df_train, df_eval]:\n",
    "    df[\"char_id_list\"] = df[\"src\"].apply(\n",
    "        lambda row: [char_to_id[char] for char in row] + [char_to_id[\"<eos>\"]]\n",
    "    )\n",
    "    df[\"label_id_list\"] = df[\"char_id_list\"].apply(zero_before_eq_sign)\n",
    "\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_eval.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "|Hyperparameter|Meaning|Value|\n",
    "|-|-|-|\n",
    "|`batch_size`|Number of data samples in a single batch|64|\n",
    "|`epochs`|Total number of epochs to train|10|\n",
    "|`embed_dim`|Dimension of the word embeddings|256|\n",
    "|`hidden_dim`|Dimension of the hidden state in each timestep of the LSTM|256|\n",
    "|`lr`|Learning Rate|0.001|\n",
    "|`grad_clip`|To prevent gradient explosion in RNNs, restrict the gradient range|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "embed_dim = 256\n",
    "hidden_dim = 256\n",
    "lr = 1e-3\n",
    "grad_clip = 1\n",
    "num_of_layers = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Batching\n",
    "- Use `torch.utils.data.Dataset` to create a data generation tool called  `dataset`.\n",
    "- The, use `torch.utils.data.DataLoader` to randomly sample from the `dataset` and group the samples into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the amount of data\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extract the input data x and the ground truth y from the data\n",
    "        x = self.sequences[\"char_id_list\"][index][:-1]\n",
    "        y = self.sequences[\"label_id_list\"][index][1:]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# collate function, used to build dataloader\n",
    "def collate_fn(batch):\n",
    "    # # shihtl> Filtering some numbers that make them never appear in your training data\n",
    "    # # shihtl> Here, the number 16 is filtered out\n",
    "    # batch = list(filter(lambda x: 16 not in x[0] and 16 not in x[1], batch))\n",
    "\n",
    "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
    "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
    "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
    "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
    "\n",
    "    # Pad the input sequence\n",
    "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(\n",
    "        batch_x, batch_first=True, padding_value=char_to_id[\"<pad>\"]\n",
    "    )\n",
    "\n",
    "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(\n",
    "        batch_y, batch_first=True, padding_value=char_to_id[\"<pad>\"]\n",
    "    )\n",
    "\n",
    "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>len</th>\n",
       "      <th>char_id_list</th>\n",
       "      <th>label_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2285313</td>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>882</td>\n",
       "      <td>14</td>\n",
       "      <td>[2, 4, 9, 10, 4, 5, 8, 3, 13, 11, 6, 15, 15, 3, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 15, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317061</td>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>[10, 14, 8, 2, 11, 9, 12, 6, 5, 12, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 5, 12, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718770</td>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>[2, 5, 8, 5, 3, 8, 3, 17, 6, 16, 4, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 4, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170195</td>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>-248</td>\n",
       "      <td>14</td>\n",
       "      <td>[5, 2, 9, 10, 5, 7, 2, 2, 11, 6, 7, 3, 4, 15, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 4, 15, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2581417</td>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>1177</td>\n",
       "      <td>12</td>\n",
       "      <td>[3, 4, 9, 4, 17, 8, 2, 6, 2, 2, 16, 16, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 16, 16, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             src   tgt  len  \\\n",
       "0     2285313  14*(43+20)=882   882   14   \n",
       "1      317061      (6+1)*5=35    35   10   \n",
       "2      718770     13+32+29=74    74   11   \n",
       "3      170195  31*(3-11)=-248  -248   14   \n",
       "4     2581417    24*49+1=1177  1177   12   \n",
       "\n",
       "                                         char_id_list  \\\n",
       "0  [2, 4, 9, 10, 4, 5, 8, 3, 13, 11, 6, 15, 15, 3, 1]   \n",
       "1              [10, 14, 8, 2, 11, 9, 12, 6, 5, 12, 1]   \n",
       "2              [2, 5, 8, 5, 3, 8, 3, 17, 6, 16, 4, 1]   \n",
       "3    [5, 2, 9, 10, 5, 7, 2, 2, 11, 6, 7, 3, 4, 15, 1]   \n",
       "4          [3, 4, 9, 4, 17, 8, 2, 6, 2, 2, 16, 16, 1]   \n",
       "\n",
       "                                     label_id_list  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 15, 3, 1]  \n",
       "1               [0, 0, 0, 0, 0, 0, 0, 0, 5, 12, 1]  \n",
       "2            [0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 4, 1]  \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 4, 15, 1]  \n",
       "4        [0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 16, 16, 1]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset(df_train[[\"char_id_list\", \"label_id_list\"]])\n",
    "ds_eval = Dataset(df_eval[[\"char_id_list\", \"label_id_list\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader of train set and eval set, collate_fn is the collate function\n",
    "dl_train = torch.utils.data.DataLoader(\n",
    "    ds_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "dl_eval = torch.utils.data.DataLoader(\n",
    "    ds_eval, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design\n",
    "\n",
    "## Execution Flow\n",
    "1. Convert all characters in the sentence into embeddings.\n",
    "2. Pass the embeddings through an LSTM sequentially.\n",
    "3. The output of the LSTM is passed into another LSTM, and additional layers can be added.\n",
    "4. The output from all time steps of the final LSTM is passed through a Fully Connected layer.\n",
    "5. The character corresponding to the maximum value across all output dimensions is selected as the next character.\n",
    "\n",
    "## Loss Function\n",
    "Since this is a classification task, Cross Entropy is used as the loss function.\n",
    "\n",
    "## Gradient Update\n",
    "Adam algorithm is used for gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, lstm_layers=2):\n",
    "        \"\"\"lstm_layers: number of LSTM layers, must be at least 2\"\"\"\n",
    "        super(CharRNN, self).__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embed_dim,\n",
    "            padding_idx=char_to_id[\"<pad>\"],\n",
    "        )\n",
    "\n",
    "        self.rnn_layer1 = torch.nn.LSTM(\n",
    "            input_size=embed_dim, hidden_size=hidden_dim, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn_layer2 = torch.nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            num_layers=lstm_layers - 1,\n",
    "        )\n",
    "\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch_x, batch_x_lens):\n",
    "        return self.encoder(batch_x, batch_x_lens)\n",
    "\n",
    "    # The forward pass of the model\n",
    "    def encoder(self, batch_x, batch_x_lens):\n",
    "        batch_x = self.embedding(batch_x)\n",
    "\n",
    "        batch_x = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            batch_x, batch_x_lens, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        batch_x, _ = self.rnn_layer1(batch_x)\n",
    "        batch_x, _ = self.rnn_layer2(batch_x)\n",
    "\n",
    "        batch_x, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_x, batch_first=True)\n",
    "\n",
    "        batch_x = self.linear(batch_x)\n",
    "\n",
    "        return batch_x\n",
    "\n",
    "    def generator(self, start_char, max_len=200):\n",
    "        # print(start_char)\n",
    "\n",
    "        char_list = [char_to_id[c] for c in start_char]\n",
    "\n",
    "        next_char = None\n",
    "\n",
    "        while len(char_list) < max_len:\n",
    "            # Pack the char_list to tensor\n",
    "            # shihtl> send the tensor to device of the model, 這樣寫是希望最下面計算有沒有 \"9\" 的時候能快一點\n",
    "            # x = torch.tensor(char_list).to(next(self.embedding.parameters()).device)\n",
    "            x = torch.tensor(char_list)\n",
    "            x = self.embedding(x)\n",
    "            x, _ = self.rnn_layer1(x)\n",
    "            x, _ = self.rnn_layer2(x)\n",
    "            y = self.linear(x)\n",
    "\n",
    "            # print(y.shape)\n",
    "\n",
    "            y = y[-1]\n",
    "\n",
    "            # print(y)\n",
    "\n",
    "            next_char = torch.argmax(y).item()\n",
    "\n",
    "            if next_char == char_to_id[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "            char_list.append(next_char)\n",
    "\n",
    "        return [id_to_char[ch_id] for ch_id in char_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CharRNN(vocab_size, embed_dim, hidden_dim, num_of_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=char_to_id[\"<pad>\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "1. The outer `for` loop controls the `epoch`\n",
    "    1. The inner `for` loop uses `data_loader` to retrieve batches.\n",
    "        1. Pass the batch to the `model` for training.\n",
    "        2. Compare the predicted results `batch_pred_y` with the true labels `batch_y` using Cross Entropy to calculate the loss `loss`\n",
    "        3. Use `loss.backward` to automatically compute the gradients.\n",
    "        4. Use `torch.nn.utils.clip_grad_value_` to limit the gradient values between `-grad_clip` &lt; and &lt; `grad_clip`.\n",
    "        5. Use `optimizer.step()` to update the model (backpropagation).\n",
    "2.  After every `1000` batches, output the current loss to monitor whether it is converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tensor_are_same(pred, ans):\n",
    "    \"\"\"比較 pred 的數值有沒有跟 ans 非 0 部分相同，如果 ans 是 0 就忽略\"\"\"\n",
    "\n",
    "    for num_pred, num_ans in zip(pred, ans):\n",
    "        if num_ans == 0:\n",
    "            continue\n",
    "        elif num_pred != num_ans:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================1_LSTM_3_0.001_vocab_by_freq_increasing===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████| 37020/37020 [08:47<00:00, 70.24it/s, loss=0.246]\n",
      "Validation epoch 1: 100%|██████████| 4114/4114 [03:14<00:00, 21.16it/s, accuracy=0.61] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss when training: 0.1379280537366867\n",
      "Accuracy when validation: 0.609994301994302\n",
      "==============================2_LSTM_3_0.001_vocab_by_freq_increasing===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████| 37020/37020 [10:02<00:00, 61.42it/s, loss=0.202]\n",
      "Validation epoch 2: 100%|██████████| 4114/4114 [03:34<00:00, 19.18it/s, accuracy=0.708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss when training: 0.19201958179473877\n",
      "Accuracy when validation: 0.7083722697056031\n",
      "==============================3_LSTM_3_0.001_vocab_by_freq_increasing===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████| 37020/37020 [09:36<00:00, 64.25it/s, loss=0.196] \n",
      "Validation epoch 3: 100%|██████████| 4114/4114 [03:00<00:00, 22.82it/s, accuracy=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss when training: 0.1231955736875534\n",
      "Accuracy when validation: 0.778412155745489\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "torch.set_printoptions(threshold=np.inf)\n",
    "\n",
    "i = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    PARAM = f\"{epoch}_LSTM_{num_of_layers}_{lr}_vocab_by_freq_increasing\"\n",
    "    print(f\"{PARAM}\".center(100, \"=\"))\n",
    "    loss_record = []\n",
    "\n",
    "    model.train()\n",
    "    # The process bar\n",
    "    bar = tqdm(dl_train, desc=f\"Train epoch {epoch}\")\n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "        # Clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_pred_y = model(batch_x.to(device), batch_x_lens)\n",
    "        batch_pred_y = batch_pred_y.transpose(\n",
    "            1, 2\n",
    "        )  # shihtl> This line of code was generated by GPT-4o.\n",
    "\n",
    "        # Input the prediction and ground truths to loss function\n",
    "        loss = criterion(batch_pred_y, batch_y.to(device))\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_value_(\n",
    "            model.parameters(), grad_clip\n",
    "        )  # gradient clipping\n",
    "\n",
    "        # Optimize parameters in the model\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_record.append(loss.item())\n",
    "\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # save the model\n",
    "    torch.save(model.state_dict(), f\"./checkpoints/{PARAM}.pt\")\n",
    "\n",
    "    # shihtl> This section of code was generated by GPT-4o.\n",
    "    # save the loss_record\n",
    "    with open(f\"./loss_data/{PARAM}_loss_record.pkl\", \"wb\") as f:\n",
    "        pickle.dump(loss_record, f)\n",
    "    # shihtl> Section end.\n",
    "\n",
    "    # Evaluate your model\n",
    "    model.eval()\n",
    "    bar = tqdm(dl_eval, desc=f\"Validation epoch {epoch}\")\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "\n",
    "        predictions = model(batch_x.to(device), batch_x_lens)\n",
    "        predictions = predictions.argmax(dim=2)\n",
    "\n",
    "        # Write your code here.\n",
    "        # Check whether the prediction match the ground truths\n",
    "        for pred, ans in zip(predictions, batch_y):\n",
    "            if two_tensor_are_same(pred, ans):\n",
    "                matched += 1\n",
    "\n",
    "        total += len(batch_y_lens)\n",
    "\n",
    "        # Compute exact match (EM) on the eval dataset\n",
    "        EM = matched / total\n",
    "        bar.set_postfix(accuracy=EM)\n",
    "\n",
    "    print(f\"Loss when training: {loss.item()}\")\n",
    "    print(f\"Accuracy when validation: {matched / total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "Use `model.generator` and provide an initial character to automatically generate a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cpu\")\n",
    "print(model.generator(\"1+1=\"))\n",
    "print(\"\".join(model.generator(\"(10+4)*2=\")))\n",
    "print(\"\".join(model.generator(\"(00+4)*2=\")))\n",
    "print(\"\".join(model.generator(\"(0+4)*2=\")))\n",
    "print(\"\".join(model.generator(\"1+1+9=\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\X6959\\AppData\\Local\\Temp\\ipykernel_17880\\4262551539.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./checkpoints/3_LSTM_3_0.001_no_id_16.pt\"))\n",
      "100%|██████████| 263250/263250 [45:57<00:00, 95.48it/s, matched_9=739, matched_no_9=121069, total_9=101460, total_no_9=161790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 9 Accuracy when validation: 0.7483095370542061\n",
      "9 Accuracy when validation: 0.007283658584663907\n"
     ]
    }
   ],
   "source": [
    "# shihtl> Evaluate the model trained excluding \"9\" which id is 16\n",
    "model = CharRNN(vocab_size, embed_dim, hidden_dim, num_of_layers).to(\n",
    "    torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "model.load_state_dict(torch.load(\"./checkpoints/3_LSTM_3_0.001_no_id_16.pt\"))\n",
    "\n",
    "matched_9 = 0\n",
    "total_9 = 0\n",
    "matched_no_9 = 0\n",
    "total_no_9 = 0\n",
    "model.eval()\n",
    "\n",
    "bar = tqdm(df_eval[[\"src\"]].values)\n",
    "\n",
    "for record in bar:\n",
    "    input_eqation = record[0][: record[0].index(\"=\") + 1]\n",
    "\n",
    "    pred = \"\".join(model.generator(input_eqation))\n",
    "\n",
    "    if pred == record and \"9\" not in record[0]:\n",
    "        matched_no_9 += 1\n",
    "    elif pred == record:\n",
    "        matched_9 += 1\n",
    "\n",
    "    if \"9\" not in record[0]:\n",
    "        total_no_9 += 1\n",
    "    else:\n",
    "        total_9 += 1\n",
    "\n",
    "    bar.set_postfix(\n",
    "        matched_no_9=matched_no_9,\n",
    "        total_no_9=total_no_9,\n",
    "        matched_9=matched_9,\n",
    "        total_9=total_9,\n",
    "    )\n",
    "\n",
    "print(f\"No 9 Accuracy when validation: {matched_no_9 / total_no_9}\")\n",
    "print(f\"9 Accuracy when validation: {matched_9 / total_9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\X6959\\AppData\\Local\\Temp\\ipykernel_17880\\666843599.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./checkpoints/3_LSTM_3_0.001.pt\"))\n",
      "100%|██████████| 263250/263250 [45:28<00:00, 96.49it/s, matched_9=76964, matched_no_9=136879, total_9=101460, total_no_9=161790]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 9 Accuracy when validation: 0.8460288027690216\n",
      "9 Accuracy when validation: 0.7585649517051054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# shihtl> Evaluate the model trained including \"9\" which id is 16\n",
    "model = CharRNN(vocab_size, embed_dim, hidden_dim, num_of_layers).to(\n",
    "    torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "model.load_state_dict(torch.load(\"./checkpoints/3_LSTM_3_0.001.pt\"))\n",
    "\n",
    "matched_9 = 0\n",
    "total_9 = 0\n",
    "matched_no_9 = 0\n",
    "total_no_9 = 0\n",
    "model.eval()\n",
    "\n",
    "bar = tqdm(df_eval[[\"src\"]].values)\n",
    "\n",
    "for record in bar:\n",
    "    input_eqation = record[0][: record[0].index(\"=\") + 1]\n",
    "\n",
    "    pred = \"\".join(model.generator(input_eqation))\n",
    "\n",
    "    if pred == record and \"9\" not in record[0]:\n",
    "        matched_no_9 += 1\n",
    "    elif pred == record:\n",
    "        matched_9 += 1\n",
    "\n",
    "    if \"9\" not in record[0]:\n",
    "        total_no_9 += 1\n",
    "    else:\n",
    "        total_9 += 1\n",
    "\n",
    "    bar.set_postfix(\n",
    "        matched_no_9=matched_no_9,\n",
    "        total_no_9=total_no_9,\n",
    "        matched_9=matched_9,\n",
    "        total_9=total_9,\n",
    "    )\n",
    "\n",
    "print(f\"No 9 Accuracy when validation: {matched_no_9 / total_no_9}\")\n",
    "print(f\"9 Accuracy when validation: {matched_9 / total_9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\X6959\\AppData\\Local\\Temp\\ipykernel_17880\\277824075.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./checkpoints/3_LSTM_3_0.001.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+=-+===================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# shihtl> Evaluate the model with 3-digit numbers\n",
    "vocab_size = 18\n",
    "embed_dim = 256\n",
    "hidden_dim = 256\n",
    "num_of_layers = 3\n",
    "\n",
    "model = CharRNN(vocab_size, embed_dim, hidden_dim, num_of_layers)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/3_LSTM_3_0.001.pt\"))\n",
    "print(\"\".join(model.generator(\"1+=\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123+456=81\n",
      "123*456=7140\n",
      "333*333=12799\n",
      "984*232=636\n",
      "(9+232)*500=1400\n",
      "(9-232)*500=-1000\n",
      "(22+68)*900=420\n",
      "(22-68)*900=-160\n",
      "(9+232)*(22+68)=1485\n",
      "(9+232)*(22-68)=-279\n",
      "(9-232)*(22+68)=147\n",
      "(9-232)*(22-68)=-465\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(model.generator(\"123+456=\")))\n",
    "print(\"\".join(model.generator(\"123*456=\")))\n",
    "print(\"\".join(model.generator(\"333*333=\")))\n",
    "print(\"\".join(model.generator(\"984*232=\")))\n",
    "print(\"\".join(model.generator(\"(9+232)*500=\")))\n",
    "print(\"\".join(model.generator(\"(9-232)*500=\")))\n",
    "print(\"\".join(model.generator(\"(22+68)*900=\")))\n",
    "print(\"\".join(model.generator(\"(22-68)*900=\")))\n",
    "print(\"\".join(model.generator(\"(9+232)*(22+68)=\")))\n",
    "print(\"\".join(model.generator(\"(9+232)*(22-68)=\")))\n",
    "print(\"\".join(model.generator(\"(9-232)*(22+68)=\")))\n",
    "print(\"\".join(model.generator(\"(9-232)*(22-68)=\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
