{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Tsung\\Programming\\GitHub\\11310CS563100_Assignments\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import random\n",
    "# import subprocess\n",
    "import warnings\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import Literal\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AddedToken\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "# from transformers import DataCollatorWithPadding\n",
    "# from transformers import TextClassificationPipeline\n",
    "# from transformers.pipelines.pt_utils import KeyDataset\n",
    "# from datasets import Dataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "# from IPython.display import FileLink, display\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_paths: list,\n",
    "        tokenizer_path: str = None,\n",
    "        voting_mode: Literal[\"mean\", \"linear\"] = \"mean\",\n",
    "        linear_layer_num: int = 0,  # if voting_mode is \"linear\"\n",
    "    ) -> None:\n",
    "        super(VotingModel, self).__init__()\n",
    "\n",
    "        self.models = [\n",
    "            AutoModelForSequenceClassification.from_pretrained(path, num_labels=1)\n",
    "            for path in model_paths\n",
    "        ]\n",
    "        self.tmp_linear = torch.nn.Linear(6, 1).to(\n",
    "            torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "        # self.tokenizer = (\n",
    "        #     AutoTokenizer.from_pretrained(tokenizer_path, trucation=True, padding=True, trunca)\n",
    "        #     if tokenizer_path\n",
    "        #     else AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "        # )\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        self.tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        self.tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "\n",
    "        assert (\n",
    "            linear_layer_num >= 0\n",
    "        ), \"linear_layer_num must be greater than or equal to 0\"\n",
    "        self.voting_mode = \"mean\" if linear_layer_num == 0 else \"linear\"\n",
    "\n",
    "        num_of_models = len(self.models)\n",
    "        if self.voting_mode == \"linear\":\n",
    "            self.linear_list = [\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(num_of_models, num_of_models), torch.nn.ReLU()\n",
    "                )\n",
    "                for _ in range(linear_layer_num - 1)\n",
    "            ] + [torch.nn.Linear(num_of_models, 1)]\n",
    "            self.linears = torch.nn.Sequential(*self.linear_list)\n",
    "            print(self.linears)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # initialize settings of models\n",
    "        for model in self.models:\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            # model.parameters().requires_grad = False  # freeze all pre-trained layers\n",
    "\n",
    "        if self.voting_mode == \"linear\":\n",
    "            self.linears.to(self.device)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.tokenizer(X, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "        X = {k: v.to(self.device) for k, v in X.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # print([model(**X) for model in self.models])\n",
    "            # y = 0\n",
    "            y = torch.stack(\n",
    "                # [self.tmp_linear(model(**X).logits) for model in self.models]\n",
    "                [model(**X).logits for model in self.models]\n",
    "            )\n",
    "            # print(y)\n",
    "\n",
    "        if self.voting_mode == \"mean\":\n",
    "            y = y.mean(dim=0)\n",
    "        elif self.voting_mode == \"linear\":\n",
    "            y = y.squeeze(2).transpose(0, 1)\n",
    "            # print(y.shape)\n",
    "            y = self.linears(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model = VotingModel(\n",
    "    [\n",
    "        \"./model/alef-b-220-regv1-pc2-deberta-v3-small-skf-s5-e4-pytorch-v1-v1/deberta-v3-small_AES2_fold_0_v1\",\n",
    "        \"./model/alef-b-220-regv1-pc2-deberta-v3-small-skf-s5-e4-pytorch-v1-v1/deberta-v3-small_AES2_fold_1_v1\",\n",
    "        \"./model/alef-b-220-regv1-pc2-deberta-v3-small-skf-s5-e4-pytorch-v1-v1/deberta-v3-small_AES2_fold_2_v1\",\n",
    "        \"./model/alef-b-220-regv1-pc2-deberta-v3-small-skf-s5-e4-pytorch-v1-v1/deberta-v3-small_AES2_fold_3_v1\",\n",
    "        \"./model/alef-b-220-regv1-pc2-deberta-v3-small-skf-s5-e4-pytorch-v1-v1/deberta-v3-small_AES2_fold_4_v1\",\n",
    "    ],\n",
    "    tokenizer_path=\"./model/alef-b-220-regv1-pc2-deberta-v3-small-skf-s5-e4-pytorch-v1-v1/output_v1/checkpoint-17396-tokenizer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    prediction  ground_truth  res_round\n",
      "0     1.705298             3        3.0\n",
      "1     2.022682             3        3.0\n",
      "2     2.941526             4        4.0\n",
      "3     2.850662             4        4.0\n",
      "4     1.825086             3        3.0\n",
      "5     3.064401             4        4.0\n",
      "6     1.126608             2        2.0\n",
      "7     1.981581             3        3.0\n",
      "8     1.353138             2        2.0\n",
      "9     1.891761             3        3.0\n",
      "10    1.240501             2        2.0\n",
      "11    1.145892             2        2.0\n",
      "12    3.103931             4        4.0\n",
      "13    1.966938             3        3.0\n",
      "14    2.009931             3        3.0\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_df = pd.read_csv(\"./dataset/kaggle/train.csv\")\n",
    "train_scores = []\n",
    "res = voting_model(train_df[\"full_text\"].tolist()[:15])\n",
    "res_round = (res + 1).round()\n",
    "# print(res.squeeze().tolist())\n",
    "# print(train_df[\"score\"].tolist()[: 5])\n",
    "\n",
    "d = {\n",
    "    \"prediction\": res.squeeze().tolist(),\n",
    "    \"ground_truth\": train_df[\"score\"].tolist()[:15],\n",
    "    \"res_round\": res_round.squeeze().tolist(),\n",
    "}\n",
    "view = pd.DataFrame(data=d)\n",
    "print(view)\n",
    "\n",
    "# testing\n",
    "# test_df = pd.read_csv(\"./dataset/kaggle/test.csv\")\n",
    "# test_scores = []\n",
    "# res = voting_model(test_df[\"full_text\"].tolist())\n",
    "# print(res)\n",
    "\n",
    "# # shihtl> Save to file \"test.csv\"\n",
    "# test_pred_df = pd.DataFrame()\n",
    "# test_pred_df[\"essay_id\"] = test_df[\"essay_id\"]\n",
    "# test_pred_df[\"score\"] = test_scores\n",
    "\n",
    "# test_pred_df.to_csv(f\"./submission.csv\", index=False)\n",
    "\n",
    "# test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ground_truth  prediction\n",
      "0       1.705298           3\n",
      "1       2.022682           3\n",
      "2       2.941526           4\n",
      "3       2.850662           4\n",
      "4       1.825086           3\n",
      "5       3.064401           4\n",
      "6       1.126608           2\n",
      "7       1.981581           3\n",
      "8       1.353138           2\n",
      "9       1.891761           3\n",
      "10      1.240501           2\n",
      "11      1.145892           2\n",
      "12      3.103931           4\n",
      "13      1.966938           3\n",
      "14      2.009931           3\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at .\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at .\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at .\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at .\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (4): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# voting_model1 = VotingModel(\n",
    "#     [\n",
    "#         \".\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\",\n",
    "#         \".\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\",\n",
    "#     ],\n",
    "# )\n",
    "# voting_model2 = VotingModel(\n",
    "#     [\n",
    "#         \".\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\",\n",
    "#         \".\\cache\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\",\n",
    "#     ],\n",
    "#     voting_mode=\"linear\",\n",
    "#     linear_layer_num=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Many people have car where they live. The thin...\n",
       "1    I am a scientist at NASA that is discussing th...\n",
       "2    People always wish they had the same technolog...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = pd.read_csv(\"./dataset/kaggle/test.csv\")\n",
    "sample_test[\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3549],\n",
      "        [0.3550],\n",
      "        [0.3537]], device='cuda:0')\n",
      "tensor([[0.1478],\n",
      "        [0.1478],\n",
      "        [0.1479]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# res1 = voting_model1(sample_test[\"full_text\"].to_list())\n",
    "# print(res1)\n",
    "# res2 = voting_model2(sample_test[\"full_text\"].to_list())\n",
    "# print(res2)\n",
    "\n",
    "# print(res[0].last_hidden_state[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print vocab dict of tokenizer\n",
    "# print(voting_model1.tokenizer.get_vocab()[\"[CLS]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del voting_model1, voting_model2\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
